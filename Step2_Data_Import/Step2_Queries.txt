1 - Query in Courses
Query
https://cognitive-search-example.search.windows.net/indexes/courses-index/docs/search?api-version=2024-05-01-preview&search=DevOps&%24top=5

Results:
{
  "@odata.context": "https://cognitive-search-example.search.windows.net/indexes('courses-index')/$metadata#docs(*)",
  "value": [
    {
      "@search.score": 1.1356969,
      "Key": "company-moodleb51ede14-025f-49ad-9e9e-44ad284eedda",
      "description": "For developers, this course will teach you how to hook your dev work into our existing CI/CD pipelines.",
      "duration": "3",
      "level": "intermediate",
      "product": "jenkins",
      "rating_average": 3.8,
      "rating_count": 101,
      "role": "developer",
      "source": "Company Moodle",
      "title": "DevOps for Dev",
      "url": "https://www.example.com/course4",
      "keyphrases": [
        "company",
        "moodle"
      ]
    },
    {
      "@search.score": 0.5408423,
      "Key": "company-moodle578a3319-aa7c-4d2f-b6a4-39e9638b0a85",
      "description": "For administrators, this course will teach you how our CI/CD pipelines work from an operations perspective",
      "duration": "5",
      "level": "intermediate",
      "product": "jenkins",
      "rating_average": 4.9,
      "rating_count": 56,
      "role": "admin",
      "source": "Company Moodle",
      "title": "DevOps for Ops",
      "url": "https://www.example.com/course5",
      "keyphrases": [
        "company",
        "moodle"
      ]
    },
    {
      "@search.score": 0.25811607,
      "Key": "ms-learn000a0d57-a0fe-4386-829c-99074d1b3b9b",
      "description": "Find out about automated testing that proves your code to be maintainable, understandable, and functioning without repetitive manual testing.",
      "duration": "82",
      "level": "beginner",
      "product": "azure-devops",
      "rating_average": 4.73,
      "rating_count": 3301,
      "role": "solution-architect",
      "source": "MS Learn",
      "title": "Run quality tests in your build pipeline by using Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/run-quality-tests-build-pipeline/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "ms",
        "learn"
      ]
    }
  ]
}

2 - Query in Cured Library

Query
https://cognitive-search-example.search.windows.net/indexes/azureblob-index/docs/search?api-version=2024-05-01-preview&search=Python&%24top=1
Results
{
  "@odata.context": "https://cognitive-search-example.search.windows.net/indexes('azureblob-index')/$metadata#docs(*)",
  "value": [
    {
      "@search.score": 2.2809408,
      "content": "\nImproving prediction with enhanced \nDistributed Memory‑based Resilient Dataset \nFilter\nSandhya Narayanan1*, Philip Samuel2 and Mariamma Chacko3\n\nIntroduction\nAnalyzing and processing massive volumes of data in different applications like sensor \ndata, health care and e-Commerce require big data processing technologies. Extracting \nuseful information from the enormous size of unstructured data is a crucial thing. As the \namount of data becomes more extensive, sophisticated pre-processing techniques are \nrequired to analyze the data. In social networking sites and other online shopping sites, \na massive volume of online product reviews from a large size of customers are available \n[1]. The impact of online product reviews affects 90% of the current e-Commerce mar-\nket [2]. Customer reviews contribute the product sale to an extent and product life in the \nmarket depends on online product recommendations.\n\nOnline feedback is one of the communication methods which gives direct suggestions \nfrom the customers [3, 4]. Online reviews and ratings from customers are another infor-\nmation source about product quality [5, 6]. Customer reviews can help to decide on a new \nsuccessful product launch. Online shopping has several advantages over retail shopping. In \nretail shopping, the customers visit the shop and receive price information but less product \n\nAbstract \n\nLaunching new products in the consumer electronics market is challenging. Develop-\ning and marketing the same in limited time affect the sustainability of such companies. \nThis research work introduces a model that can predict the success of a product. A \nFeature Information Gain (FIG) measure is used for significant feature identification \nand Distributed Memory-based Resilient Dataset Filter (DMRDF) is used to eliminate \nduplicate reviews, which in turn improves the reliability of the product reviews. The \npre-processed dataset is used for prediction of product pre-launch in the market using \nclassifiers such as Logistic regression and Support vector machine. DMRDF method is \nfault-tolerant because of its resilience property and also reduces the dataset redun-\ndancy; hence, it increases the prediction accuracy of the model. The proposed model \nworks in a distributed environment to handle a massive volume of the dataset and \ntherefore, it is scalable. The output of this feature modelling and prediction allows the \nmanufacturer to optimize the design of his new product.\n\nKeywords: Distributed Memory-based, Resilient Distribution Dataset, Redundancy\n\nOpen Access\n\n© The Author(s) 2020. This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and \nthe source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material \nin this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material \nis not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the \npermitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creat iveco \nmmons .org/licen ses/by/4.0/.\n\nRESEARCH\n\nNarayanan et al. J Big Data            (2020) 7:13  \nhttps://doi.org/10.1186/s40537‑020‑00292‑y\n\n*Correspondence:   \nnairsands@gmail.com \n1 Information Technology, \nSchool of Engineering, \nCochin University of Science \n& Technology, Kochi 682022, \nIndia\nFull list of author information \nis available at the end of the \narticle\n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40537-020-00292-y&domain=pdf\n\n\nPage 2 of 15Narayanan et al. J Big Data            (2020) 7:13 \n\ninformation from shop owners. On the other hand, online shopping sites give product \nreviews and previous customer feedbacks without extra cost and effort for the customers \n[7–10].\n\nInvesting in poor quality products potentially affects an industry’s brand loyalty and this \nstrategy should be changed by the eCommerce firms [5, 11]. Consumer product success \ndepends on different criteria, such as the quality of the product and marketing strategies. \nThe users should provide their valuable and accurate reviews about the products [12]. Cus-\ntomers bother to give reviews about products, whether they liked it or not. If the users \nprovide reviews, then other retailers can create some duplicated reviews [13, 14]. In online \nmarketing, the volume and value of product reviews are examined [15, 16]. The number \nof the product reviews on the shopping sites, blogs and forums has increased awareness \namong the users. This large volume of the reviews leads to the need for significant data \nprocessing methods [17, 18]. The value is the rating on the products. The ratio of positive to \nnegative reviews about the product leads to the quality of the product [19, 20].\n\nFeature selection is a crucial phase in data pre-processing [21]. Selecting features from \nan un-structured massive volume of data reduce the model complexity and improves the \nprediction accuracy. Different feature selection methods existing are the filter, wrapper and \nembedded. The wrapper feature selection method evaluates the usefulness of the feature \nand it depends on the performance of the classifier [22]. The filter method calculates the \nrelevance of the features and analyzes data in a univariate manner. The embedded process \nis similar to the wrapper method. Embedded and wrapper methods are more expensive \ncompared to the filter method. The state-of-art methods in customer review analysis gener-\nally discuss on categorizing positive and negative reviews using different natural language \nprocessing techniques and spam reviews recognition [23]. Feature selection of customer \nreviews increases prediction accuracy, thereby improves the model performance.\n\nAn enhanced method, which is a combination of filter and wrapper method is proposed \nin this work, which focuses on product pre-launch prediction with enhanced distributive \nfeature selection method. Since many redundant reviews are available on the web in large \nvolumes, a big data processing model has been implemented to filter out duplicated and \nunreliable data from customer reviews in-order to increase prediction accuracy. A scalable \nbig data processing model has been applied to predict the success or failure of a new prod-\nuct. The realization of the model has been done by Distributed Memory-based Resilient \nDataset Filter with prediction classifiers.\n\nThis paper is organized as follows. “Related work” section discusses related work. “Meth-\nodology” section contains the proposed methodology with System design, Resilient Distrib-\nuted Dataset and Prediction using classifiers. “Results and discussions” section summarizes \nresults and discussion. The conclusion of the paper is shown in “Conclusion and future \nwork” section.\n\nRelated work\nMakridakis et al. [24] illustrate that machine learning methods are alternative methods \nfor statistical analysis of multiple forecasting field. Author claims that statistical methods \nare more accurate than machine learning [25] methods. The reason for less accuracy is \nthe unknown values of data i.e., improper knowledge and pre-processing of data.\n\n\n\nPage 3 of 15Narayanan et al. J Big Data            (2020) 7:13  \n\nDifferent works have been implemented using the Matrix factorization (MF) [14] \nmethod with collaborative filtering [26]. Hao et al. [15] focused on a work based on the \nfactorization of the user rating matrix into two vectors, i.e., user latent and item latent \nwith low dimensionality. The sum of squared distance can be minimized by training a \nmodel that can find a solution using Stochastic Gradient Decent [27] or by least squares \n[28]. Salakhutdinov et al. [29] proposed a method that can be scaled linearly by probabil-\nity related matrix factorization on a big volume of datasets and then comparing it with \nthe single value decomposition method. This matrix factorization outperforms other \nprobability factorization methods like Bayesian-based probabilistic analysis [29] and \nstandard probability-based matrix factorization methods. A conventional approach, like \ntraditional collaborative Filtering [13, 30] method depends on customers and items. The \nuser item matrix factorization technique has been used for implementation purpose. \nIn the recommender system, there is a limitation in the sparsity problem and cold start \nproblem. In addition to the user item matrix factorization method, various analyses and \napproaches have been implemented to solve these recommendation issues.\n\nWietsma et al. [31] proposed a recommender system that gives information about the \nmobile decision aid and filtering function. This has been implemented with a study of \n29 features of student user behavior. The result shows the correlation among the user \nreviews and product reviews from different websites. Jianguo Chen et al. [32] proposed \na recommendation system for the treatment and diagnosis of the diseases. For cluster \nanalysis of disease symptoms, a density-peaked method is adopted. A rule-based apriori \nalgorithm is used for the diagnosis of disease and treatment. Asha et al. [33] proposed \nthe Gini-index feature method using movie review dataset. The sentimental analysis \nof the reviews are performed and opinion extraction of the sentences are done. Gini-\nindex impurity measure improves the accuracy of the polarity prediction by sentimental \nanalysis using Support vector machine [34, 35]. Depending on the frequency of occur-\nrence of a word in the document, the term frequency is calculated and opinion words \nare extracted using the Gini-index method. In this method, high term frequency words \nare not included, as it decreases the precision. The disadvantage of this method is that \nfor the huge volume of data, the prediction accuracy decreases.\n\nLuo et al. [36] proposed a method based on historical data to analyze the quality of \nservice for automatic service selection. Liu et al. [37] proposed a system in a mobile envi-\nronment for movie rating and review summarization. The authors used Latent Semantic \nAnalysis (LSA-based) method for product feature identification and feature-based sum-\nmarization. Statistical methods [38] have been used for identifying opinion words. The \ndisadvantage of this method is that LSA-based method cannot be represented efficiently; \nhence, it is difficult to index based on individual dimensions. This reduces the prediction \naccuracy in large datasets.\n\nLack of appropriate computing models for handling huge volume and redundancy in \ncustomer review datasets is a major challenge. Another major challenge handled in the \nproposed work is the existence of a pre-launch product in the industry based on the \nproduct features, which can be predicted based on the customer feedback in the form \nof reviews and ratings of the existing products. This prediction helps to optimize the \ndesign of the product to improve its quality with the required product features. Many \nof the relational database management systems are handling structured data, which is \n\n\n\nPage 4 of 15Narayanan et al. J Big Data            (2020) 7:13 \n\nnot scalable for big data that handles a large volume of unstructured data. This proposed \nmodel solves the problem of redundancy in a huge volume of the dataset for better pre-\ndiction accuracy.\n\nMethodology\nA pre-launch product prediction using different classifiers has been analysed by huge \ncustomer review and rating dataset. The product prediction is done through the phases \nconsisting of data collection phase, feature selection and duplicate data removal, build-\ning prediction classifier, training as well as testing.\n\nFigure 1 describes the various stages in system design of the model. The input dataset \nconsists of multivariate data which includes categorical, real and text data. Input dataset \nis fed for data pre-processing. Data pre-processing consists of feature selection, redun-\ndancy elimination and data integration which is done using Feature Information Gain \nand Distributed Memory-based Resilient Dataset Filter approach. The cleaned dataset \nis trained using classification algorithms. The classifiers considered for training are Sup-\nport Vector Machine (SVM) and Logistic Regression (LR). Further the dataset is tested \nfor pre-launch prediction using LR and SVM.\n\nData collection phase\n\nThis methodology can be applied for different products. Several datasets like Ama-\nzon and flip cart customer reviews are available as public datasets [39–41]. The data-\nset of customer reviews and ratings of seven brands of mobile phones for a period of \n24 months are considered in this work. The mobile phones product reviews are chosen \nbecause of two reasons. New mobile phones are launched into the market industry day \nby day which is one of the unavoidable items in everyone’s life. Market sustainability for \nthe mobile phones is very low.\n\nTable  1 shows a sample set of product reviews in which input dataset consists of \nuser features and product features. User features consists of Author, ReviewID and \nTitle depending on the user. Product feature consists of Product categories, Overall \nratings and Review Content. Since mobile phone is taken as the product, the catego-\nrization is done according to the features such as Battery life, price, camera, RAM, \n\nData collection \n\nCategorical\n\nText\n\nReal\n\nData Pre-\nprocessing\n\nFeature \nIdentification\n\nRedundancy\nRemoval\n\nData \nIntegration\n\nTraining \nDataset Using \nclassification \nalgorithms\n\nSupport \nVector \n\nLogistic \nRegression\n\nTesting Dataset \nUsing \n\nclassification \nalgorithms\n\nLogistic \nRegression\n\nSupport \nVector \n\nFig. 1 Product prelaunch prediction System Design\n\n\n\nPage 5 of 15Narayanan et al. J Big Data            (2020) 7:13  \n\nprocessor, weight etc. Some features are given a priority weightage depending on the \nproduct and user requirements. Input dataset with JSON file format is taken.\n\nDataset pre‑processing\n\nIn data pre-processing, feature selection plays a major role. In the product review \ndataset of a mobile phone, a large number of features exist. Identifying a feature from \ncustomer reviews is important for this model to improve the prediction accuracy. \nEnhanced Feature Information Gain measure has been implemented to identify sig-\nnificant feature.\n\nFeatures are identified based on the content of the product reviews, ratings of the \nproduct reviews and opinion identification of the reviews. Ratings of the product \nreviews can be further categorized based on a rating scale of 5 (1—Bad, 2—Average, \n3—Good, 4—very good, 5—Excellent). For opinion identification of the product, the \npolarity of extracted opinions for each review is classified using Senti-WordNet [42].\n\nFeature Information Gain measures the amount of information of a feature \nretrieved from a particular review. Impurity which is the measure of reliability of fea-\ntures in the input dataset should be reduced to get significant features. To measure \nfeature impurity, the best information of a feature obtained from each review is calcu-\nlated as follows\n\n• Let Pi be the probability of any feature instance \n(\n\nf\n)\n\n of k feature set F =\n{\n\nf1, f2, . . . fk\n}\n\n \nbelonging to  ith customer review Ri , where i varies from 1 to N.\n\n• Let N denotes the total number of customer reviews.\n• Let OR denotes the polarity of extracted opinions of the Review.\n• Let SR denotes product rating scale of review (R).\n\nTable 1 Sample set of Product Reviews\n\n\n\nPage 6 of 15Narayanan et al. J Big Data            (2020) 7:13 \n\nThe information of a feature with respect to review rating and opinion is denoted by \nIf\n\nExpected information gain of the feature denoted as Ef\n\nReview Feature Impurity R(I) is calculated as\n\nThen Feature Information Gain (�G) to find out significant features are calculated \nas\n\nFeatures are selected based on the �G value and those with an Information gain \ngreater than 0.5 is selected as a significant feature. Table 2 shows the significant fea-\nture from customer reviews and ratings.\n\nNext step is to eliminate the redundant reviews and to replace null values of an \nactive customer from the customer review dataset using an enhanced big data pro-\ncessing approach. Reviews with significant features obtained from feature identifica-\ntion are considered for further processing.\n\n(1)If = log2\n\n(\n\n1\n\nP(R = F)\n\n)\n\n∗ OR ∗ SR.\n\n(2)Ef =\n\nN\n∑\n\ni=1\n\n−Pi(R = F).\n∥\n\n∥If\n∥\n\n∥\n\n1\n.\n\n(3)R(I) = −\n\nN\n∑\n\ni=1\n\nPi.log2Ef .\n\n(4)�G = R(I)−\n\nN\n∑\n\ni=1\n\n[(\n\nOR\n\nN\n∗ Ef\n\n)\n\n−\n\n(\n\nSR\n\nN\n∗ Ef\n\n)]\n\n.\n\nTable 2 Significant Features from Customer Reviews and Ratings\n\nNo Customer reviewed features No Customer reviewed features\n\n1 Author 17 RAM\n\n2 Title 18 Sim type\n\n3 ReviewID 19 Product category\n\n4 Content 20 Thickness\n\n5 Product brand 21 Weight of mobile phone\n\n6 Ratings 22 Height\n\n7 Battery life 23 Product type\n\n8 Price 24 Product rating\n\n9 Feature information gain 25 Front camera\n\n10 Review type 26 Back camera\n\n11 Product display 27 Opinion of review\n\n12 Processor 28 Multi-band\n\n13 Operating system 29 Network support\n\n14 Water proof 30 Quick charging\n\n15 Rear camera 31 Finger sensor\n\n16 Applications inbuilt 32 Internal storage\n\n\n\nPage 7 of 15Narayanan et al. J Big Data            (2020) 7:13  \n\nResilient Distributed Dataset\n\nResilient Distributed Dataset (RDD) [43] is a big data processing approach, which allows \nto store cache chunks of data on memory and persevere it as per the requirements. \nThe in-memory data caching is supported by RDD. Variety of jobs at a point of time \nis another challenge which is handled by RDD. This method deals with chunks of data \nduring processing and analysis. RDD can also be used for machine learning supported \nsystems as well as in big data processing and analysis, which happens to be an almost \npervasive requirement in the industry.\n\nIn the proposed method the main actions of RDD are:\n\n• Reduce (β): Combine all the elements of the dataset using the function β.\n• First (): This function will return the first element\n• takeOrdered(n): RDD is returned with first ‘n’ elements.\n• saveAsSequenceFile(path): the elements in the dataset to be written to the local file \n\nsystem with given path.\n\nThe main Transformations of RDD are:\n\n• map(β): Elements from the input file is mapped and new dataset is returned through \nfunction β.\n\n• filter(β): New dataset is returned if the function β returns true.\n• groupBykey(): When called a dataset of (key, value) pairs, this function returns a \n\ndataset of (key, value) pairs.\n• ReduceBykey(β): A (key, value) pair dataset is returned, where the values of each key \n\nare combined using the given reduce function β.\n\nIn the proposed work an enhanced Distributed Memory-based Resilience Dataset \nFilter (DMRDF) is applied. DMRDF method have long Lineage and it is recomputed \nthemselves using prior information, thus it achieves fault-tolerance. DMRDF has been \nimplemented to remove the redundancy in the dataset for product pre-launch predic-\ntion. This enhanced method is simple and fast.\n\n• Let the list of n customers represented as C = {c1, c2, c3 . . . , cn}\n\n• Let the list of N reviews be represented as R = {r1, r2, r3 . . . , rN }\n\n• Let x significant features are identified from feature set (F  ) represented as Fx ⊂ F\n\n• An active customer consists of significant feature having information Gain value \ndenoted by �G\n\nIn the DMRDF method, a product is chosen and its customer reviews are found out. \nEliminate customers with similar reviews on the selected product and also reviews \nwith insignificant features. Calculate the memory-based Resilient Dataset Filter score \nbetween each of the customer reviews with significant features.\n\nLet us consider a set C of ‘n’ number of customers, the set R of ‘N’ number of reviews and \na set of significant features ′F ′\n\nx are considered. The corresponding vectors are represented \nas KC , KR and KFx . Then KRi is represented using a row vector and KFj is represented using \nthe column vector. Each entry KCm denote the number of times the  mth review arrives in \n\n\n\nPage 8 of 15Narayanan et al. J Big Data            (2020) 7:13 \n\ncustomers. The similarities between ith review of mth customer is found out using  L1 norm \nof KRi and KCm . The Distributed Memory-based resilient filter score δ is calculated using the \nEq. (5).\n\nThe δ score is calculated for each customer review whereas the score lies between [0,1]. \nThe significant features are found out using Eq. 4. For customer reviews without significant \nfeatures, �G value will be zero. The reviews with δ score value 0 are found to be insignificant \nwithout any significant feature or opinion and hence those reviews are eliminated and not \nconsidered for further processing in the work. More than one Distributed Memory-based \nresilient filter score value is identified then the second occurrence of the review is consid-\nered as duplicate.\n\nPrediction classifiers\n\nLogistic regression and Support Vector Machine classifiers are the supervised machine \nlearning approaches used in the proposed work for product pre-launch prediction.\n\nLogistic regression (LR)\n\nWe have implemented proposed model using logistic regression analysis for prediction. \nThis model predicts the failure or success of a new product in the market by analysing \nselected product features from customer reviews. A case study has been conducted using \nthe dataset of customer reviews of mobile phones. Success or failure is the predictor vari-\nable used for training and testing the dataset. For training the model 75% of the dataset is \nused and for testing the model, remaining 25% is used.\n\n• Let p be the prediction variable value, assigning 0 for failure and 1 for success.\n• p0 is the constant value.\n• b is the logarithmic base value.\n\nThen the logit function is,\n\nThen the Logistic regression value γ is shown in Eq. (7),\n\n(5)δ =\n\nN\nn\n�\n\ni = 1\n\nm = 1\n\n\n\n\n\n�\n\nKRi ∗\n\n�\n\n�x\nj=1 KFj\n\n��\n\n∗ KCm\n\nKRi · KCm\n\n\n\n ∗ |�G|\n\n(6)\nL0 = b\n\np0+p\nx\n∑\n\ni=1\n\nfi\n\n(7.1)γ =\nL0\n\n(\n\nbp0+p\n∑x\n\ni=1 fi\n)\n\n+ 1\n\n(7.2)=\n1\n\n1+ b\n−\n\n(\n\nb\np0+p\n\n∑x\ni=1\n\nfi\n)\n\n\n\nPage 9 of 15Narayanan et al. J Big Data            (2020) 7:13  \n\nThe probability value of γ lies between [0,1]. In this work, if this value is greater than 0.5 \nthe pre-launch prediction of the product is considered as success and for values less than \n0.5, it is considered as failure.\n\nSupport Vector Machine (SVM)\n\nSVM is the supervised machine learning method, used to learn from set of data to get new \nskills and knowledge. This classification method can learn from data features relationships \n( zi ) and its class \n\n(\n\nyi\n)\n\n that can be applied to predict the success or failure class the product \nbelongs to.\n\n• For a set T  of t training feature vectors, zi ∈ RD, where i = 1 to t.\n• Let yi ∈ {+1,−1} , where +1 belongs to product success class and -1 belongs to product \n\nfailure class.\n• The data separation occurs in the real numbers denoted as X in the D dimensional \n\ninput space.\n• Let w be the hyper plane normal vector element, where w ∈ XD.\n\nThe hyper plane is placed in such a way that distance between the nearest vectors of the \ntwo classes to the hyperplane should be maximum. Thus, the decision hyper plane is calcu-\nlated as,\n\nThe conditions for training dataset d ∈ X , is calculated as\n\nTo maximize the margin the value of w should be minimized.\nThe products in the positive one class (+1) are considered as successful products, [from \n\nEq. (9)] and those in the negative one class (−1) [from Eq. (10)] are in failure class.\n\nExperimental setup\n\nThe proposed system was implemented using Apache Spark 2.2.1 framework. Spark pro-\ngramming for python using PySpark version 2.1.2, which is the Spark python API has been \nused for the application development. An Ubuntu running Apache web server using Web \nServer Gateway Interface is used. Amazon Web Services is used to run some components \nof the software system large servers (nodes), having two Intel Xeon E5-2699V4 2.2 G Hz \nprocessors (VCPUs) with 4 cores and 16 GB of RAM on different Spark cluster configura-\ntions. According to the scalability requirements the software components can be config-\nured and can run on separate servers.\n\n(8)α(w) =\n2\n\n�w�\n\n(9)wtzi + d ≥ 1, where yi = +1.\n\n(10)wtzi + d ≤ −1, whereyi = yi − 1.\n\n\n\nPage 10 of 15Narayanan et al. J Big Data            (2020) 7:13 \n\nResults and discussions\nTo evaluate our prediction system several case studies have been conducted. Support \nVector Machine and Logistic regression classifiers are employed to perform the predic-\ntion. Most significant customer review features are used to analyse the system perfor-\nmance. The prediction accuracy evaluation is taken as one of the system design factors. \nThe system response time is another major concern for big data processing system. In \nthe customer review feature identification, we propose feature information gain and \nDMRDF approach to identify significant features and to eliminate redundant customer \nreviews from the input dataset.\n\nFigure  2 illustrates significant features required for the mobile phone sustainability. \nCustomer reviews and ratings of 7 brands of mobile phones are identified and evalu-\nated with DMRDF using SVM and LR. The graph shows the significant features identi-\nfied by the model against the percentage of customers whose reviews are analysed. 88% \nof the customers identified internal storage as a significant feature. Product price has \nbeen identified by 79% of customers as significant feature. With this evaluation customer \nrequirements for a product can be analysed in a better manner, thus can optimize the \ndesign of the product for better product quality and for product sustainability in the \nindustry.\n\nFigure 3 shows the comparison of the processing time taken by the proposed model \nwith different dataset size against that of the state of art techniques. DMRDF method \ntakes less time for completion of the application compared to other gini-index and latent \nsemantic analysis methods. Hence the proposed model is fast and scalable. It provides a \nhigh-speed processing performance with large datasets. This shows the DMRDF applica-\nbility in big data analytics, whereas gini-index and LSA-based methods processing time \nis larger for large volume of dataset. From the Fig. 3 it can be seen that with 9 GB dataset \ntime taken for prediction using LSA-based model, Gini-index model and DMRDF model \nis 342 s, 495 s and 156 s respectively. With 18 GB dataset time taken for prediction using \nLSA-based model, Gini-index model and DMRDF model 740 s, 910 s and 256 s respec-\ntively. Gini-index and LSA-based methods time taken for 18 GB dataset is twice that of \n9 GB dataset. But for DMRDF model time taken for 18 GB dataset is 1.6 times that of \n\n79%\n\n15%\n\n45%\n35%\n\n22%\n\n40%\n\n22%\n\n39%\n\n88%\n\n53%\n\n21%\n\n61%\n\n0%\n10%\n20%\n30%\n40%\n50%\n60%\n70%\n80%\n90%\n\n100%\n\nPe\nrc\n\nen\nta\n\nge\n o\n\nf C\nus\n\nto\nm\n\ner\ns\n\nIden�fied Significant Features\nFig. 2 Identified Significant Features from Customer reviews and Ratings\n\n\n\nPage 11 of 15Narayanan et al. J Big Data            (2020) 7:13  \n\n9 GB dataset and also it is 3 times lesser than Gini-index method. DMRDF model has \nmore advantage compared to the other state of art techniques in the case of application \nexecution and performance.\n\nThe reliability of the methods considered for the pre-launch prediction depends on \nprecision [44], recall and prediction accuracy measurement. Table 5 shows a comparison \nof precision, recall and accuracy measures of DMRDF, Gini-index and LSA-based meth-\nods with Support Vector Machine and Logistic Regression classifiers using customer \nreviews dataset over a period of 24 months. The results shown in Table 3 are best proved \nusing DMRDF with Support Vector Machine classification with prediction accuracy of \n95.4%. The DMRDF outperforms LSA-based and Gini-index methods in P@R, R@R and \nPA measures. Using proposed method, true positive (TP), false positive (FP), true nega-\ntive (TN) and false negative (FN) are found out. The prediction accuracy (PA), precision \n(P@R) and recall (R@R) are computed using Eqs. (10), (11), and (12) respectively.\n\n(10)PA =\nTP + TN\n\nTP + TN + FP + FN\n\n0\n\n100\n\n200\n\n300\n\n400\n\n500\n\n600\n\n700\n\n800\n\n900\n\n1000\n\n1GB 5GB 9GB 13GB 18GB\n\nGini-index\n\nDMRDF\n\nLSA-based\n\nTi\nm\n\ne \nTa\n\nke\nn \n\nin\n se\n\nc\n\nDataset size\nFig. 3 Dataset Size versus Processing Time Graph\n\nTable 3 Performance comparison of the proposed model with state of art techniques\n\nClassifier Support vector machine\n\nMethod used P@R (precision) PA % \n(prediction \naccuracy)\n\nDMRDF 0.941 0.92 95.4\n\nLSA-based 0.894 0.79 87.5\n\nGini-index 0.66 0.567 83.2\n\nClassifier Logistic regression\n\nMethod used P@R R@R % PA %\n\nDMRDF 0.915 0.849 93.5\n\nLSA-based 0.839 0.753 83\n\nGini-index 0.62 0.52 79.8\n\n\n\nPage 12 of 15Narayanan et al. J Big Data            (2020) 7:13 \n\nUsing DMRDF with SVM classifier and LR classifier, the prediction accuracy varia-\ntions are less compared to LSA-based and Gini-index methods. Hence DMRDF out-\nperforms the other two methods for customer review feature prediction.\n\nFurthermore Fig.  4, shows the DMRDF, LSA-based and Gini-index approaches as \napplied to the customer reviews and ratings datasets for 3, 6, 12, 18 and 24 months. \nIn DMRDF many features may appear in different customer review aspects, hence \nperformance evaluation will not consider duplicate customer reviews. In Gini- index, \nfeatures are extracted based on the polarity of the reviews and for large dataset P@R \nand R@R are less. The results show that DMRDF method outperforms the other two \nmethods in big data analysis. Gini-index approach does not perform well in customer \nreview feature prediction.\n\nConclusion and future work\nTechnological development in this era brings new challenges in artificial intelligence \nlike prediction, which is the next frontier for innovation and productivity. This work \nproposes the implementation of a scalable and reliable big data processing model \n\n(11)P@R =\nTP\n\nTP + FP\n\n(12)R@R =\nTP\n\nTP + FN\n\na SVM b SVM \n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\n0.9\n\n1\n\n1.1\n\n3 6 12 18 24\n\nP@\nR\n\nReview in Months\n\nLSA-based DMRDF Gini-index\n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\n0.9\n\n1\n\n1.1\n\n3 6 12 18 24\n\nR@\nR\n\nReview in Months\n\nLSA-based DMRDF Gini-index\n\nc Logistic Regression d Logistic Regression\n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\n0.9\n\n1\n\n1.1\n\n3 6 12 18 24\n\nP@\nR\n\nReview in Months\n\nLSA-based DMRDF Gini-index\n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\n0.9\n\n1\n\n1.1\n\n3 6 12 18 24\n\nR@\nR\n\nReview in Months\n\nLSA-based DMRDF Gini-index\n\nFig. 4 Precision and Recall of DMRDF, LSA-based and Gini-index methods using SVM and LR classifiers\n\n\n\nPage 13 of 15Narayanan et al. J Big Data            (2020) 7:13  \n\nwhich identify significant features and eliminates redundant data using Feature Infor-\nmation Gain and Distributed Memory-based Resilient Dataset Filter method with \nLogistic Regression and Support Vector Machine prediction classifiers. A compari-\nson of the analysis has been conducted with state of art techniques like Gini-index \nand LSA-based approaches. The prediction accuracy, precision and recall of DMRDF \nmethod outperforms the other methods. Results show that the prediction accuracy \nof the proposed method increases by 10% using significant feature identification and \nelimination of redundancy from dataset compared to state of art techniques. Large \nfeature dimensionality reduces the prediction accuracy of the LSA-based method \nwhere as number of significant features plays an important role in prediction model-\nling. Results show that proposed DMRDF model is scalable and with huge volume of \ndataset model performance is good as well as time taken for processing the applica-\ntion is less compared to state of art techniques.\n\nResilience property of DMRDF method have long lineage, hence this can achieve \nfault-tolerance. DMRDF model is fast because of the in-memory computation \nmethod. Proposed design can be extended to other product feature identification big \ndata processing domains. As a future work, the model may be developed to make real \ntime streaming predictions through a unified API that searches customer comments, \nratings and surveys from different reliable online websites concurrently to obtain syn-\nthesis of sentiments with an information fusion approach. Since the statistical prop-\nerties of customer reviews and ratings vary over time, the performance of machine \nlearning algorithms can also come down. To cope with the limitations of deep learn-\ning matrix factorization integrated with DMRDF can be adapted.\n\nAbbreviations\nDMRDF: Distributed Memory-based Resilient Dataset Filter; FIG: Feature information gain; RDD: Resilient distributed \ndataset; SVM: Support vector machine; LR: Logistic regression; LSA: Latent semantic analysis; PA: Prediction accuracy; \nP@R: Precision; R@R: Recall; MF: Matrix factorization.\n\nAcknowledgements\nNot applicable.\n\nAuthors’ contributions\nSN designed and implemented the model for Pre-launch product prediction. SN analysed and interpreted the customer \nreviews and ratings dataset regarding the pre-launch product prediction. PS supervised the design, implementation \nand analysis of the model for pre-launch product prediction. MC was a major contributor in writing the manuscript. All \nauthors read and approved the final manuscript.\n\nFunding\nNot applicable.\n\nAvailability of data and materials\nThe datasets generated and/or analysed during the current study are available in the Kaggle repository. [snap.stanford.\nedu/data/web-Amazon.html] [40] and [http://www.kaggl e.com/Promp tClou dHQ/flipk art-produ cts] [39].\n\nCompeting interests\nThe authors declare that they have no competing interests.\n\nAuthor details\n1 Information Technology, School of Engineering, Cochin University of Science & Technology, Kochi 682022, India. \n2 Department of Computer Science, Cochin University of Science & Technology, Kochi 682022, India. 3 Department \nof Ship Technology, Cochin University of Science & Technology, Kochi 682022, India. \n\nReceived: 25 October 2019   Accepted: 17 February 2020\n\nhttp://www.kaggle.com/PromptCloudHQ/flipkart-products\n\n\nPage 14 of 15Narayanan et al. J Big Data            (2020) 7:13 \n\nReferences\n 1. Lau RY, Liao SY, Kwok RC, Xu K, Xia Y, Li Y. Text mining and probabilistic modeling for online review spam detection. \n\nACM Trans Manag Inform Syst. 2011;2(4):25.\n 2. Lin X, Li Y, Wang X. Social commerce research: definition, research themes and the trends. Int J Inform Manag. \n\n2017;37:190–201.\n 3. Matos CAD, Rossi CAV. Word-of-mouth communications in marketing: a meta-analytic review of the antecedents \n\nand moderators. J Acad Market Sci. 2008;36(4):578–96.\n 4. Jeon S, et al. Redundant data removal technique for efficient big data search processing. Int J Softw Eng Appl. \n\n2013;7.4:427–36.\n 5. Dave K, Lawrence S, and Pennock D. Mining the peanut gallery: opinion extraction and semantic classification of \n\nproduct reviews. WWW’2003.\n 6. Zhou Y, Wilkinson D, Schreiber R, Pan R. Large-scale parallel collaborative filtering for the netflix prize. 2008. p. \n\n337–48. https ://doi.org/10.1007/978-3-540-68880 -8_32.\n 7. Zhang KZK, Benyoucef M. Consumer behavior in social commerce: a literature review. Dec Support Syst. \n\n2016;86:95–108.\n 8. Cui Geng, Lui Hon-Kwong, Guo Xiaoning. The effect of online consumer reviews on new product sales. Int J Electron \n\nComm. 2012;17(1):39–58.\n 9. Manek AS, Shenoy PD, Mohan MC, et al. Detection of fraudulent and malicious websites by analysing user reviews \n\nfor online shopping websites. Int J Knowl Web Intell. 2016;5(3):171–89. https ://doi.org/10.1007/s1128 0-015-0381-x.\n 10. Singh S, and Singh N. Big data analytics. In: Proceedings of the 2012 international conference on communication, \n\ninformation & computing technology (ICCICT), institute of electrical and electronics engineers (IEEE). 2012. p. 1–4. \nhttp://dx.doi.org/10.1109/iccic t.2012.63981 80.\n\n 11. Demchenko Yuri et al. Addressing big data challenges for scientific data infrastructure. In: IEEE 4th Int. conference \ncloud computing technology and science (CloudCom). 2012.\n\n 12. Sihong Xie, Guan Wang, Shuyang Lin and Yu Philip S. Review spam detection via time-series pattern discovery. In: \nACM Proceedings of the 21st international conference companion on World Wide Web. 2012. p. 635–6.\n\n 13. Koren Y, Bell R, Volinsky C. matrix factorization technique for recommender systems. Computer. 2009;8:30–7.\n 14. Salakhutdinov R, Mnih A, & Hinton G. Restricted boltzmann machines for collaborative filtering. In: Proc. of the 24th \n\nInt. conference on machine learning. 2007. p. 791–8.\n 15. Hao MA, King I, Lyu MR. Learning to recommend with explicit and implicit social relations. ACM Trans Intell Syst \n\nTechnol. 2011;2(3):29.\n 16. Bandakkanavar V, Ramesh M, Geeta V. A survey on detection of reviews using sentiment classification of methods. \n\nIJRITCC. 2014;2(2):310–4.\n 17. Gu V, and Li H. Memory or time—performance evaluation for iterative operation on hadoop and spark. In: Proc. of \n\nthe 2013 IEEE 10th Int. Con. on high-performance computing and communications. 2013. https ://doi.org/10.1109/\nhpcc.and.euc.2013.106.\n\n 18. Zhang Hanpeng, Wang Zhaohua, Chen Shengjun, Guo Chengqi. Product recommendation in online social net-\nworking communities—an empirical study of antecedents and a mediator. J Inform Manag. 2019;56(2):185–95.\n\n 19. Ghose A, Ipeirotis PG. Designing novel review ranking systems: predicting the usefulness and impact of reviews. In: \nInt Conference Electron Comm ACM. 2007. p. 303–10.\n\n 20. Chong AY, Ch’ng E, Liu MJ, Li B. Predicting consumer product demands via Big Data: the roles of online promotional \nmarketing and online reviews. Int J Prod Res. 2015;55:1–15. https ://doi.org/10.1080/00207 543.2015.10665 19.\n\n 21. Yang H, Fujimaki R, Kusumura Y, & Liu J. Online Feature Selection. In: Proceedings of the 22nd ACM SIGKDD Int. \nConference on KDD ‘16, 2016. https ://doi.org/10.1145/29396 72.29398 81.\n\n 22. Breese JS, Heckerman D, and Kadie C. Empirical analysis of predictive algorithms for collaborative filtering. In: Proc. \nof the 14th Conf. on Uncertainty in Artifical Intelligence, 1998.\n\n 23. Mukherjee A, Kumar A, Liu B, Wang J, Hsu M, Castellanos M, Ghosh R. Spotting opinion spammers using behavioral \nfootprints. In: Proc. of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining \nChicago, ACM. 2013. p. 632–40.\n\n 24. Makridakis S, Spiliotis E, Assimakopoulos V. Statistical and Machine Learning forecasting methods: concerns and \nways forward. PLoS ONE. 2018;13(3):e0194889. https ://doi.org/10.1371/journ al.pone.01948 89.\n\n 25. Imon A, Roy C, Manos C, Bhattacharjee S. Prediction of rainfall using logistic regression. Pak J Stat Oper Res. 2012. \nhttps ://doi.org/10.18187 /pjsor .v8i3.535.\n\n 26. Chen T, Zhang W, Lu Q, Chen K, Zheng Z, Yu Y. SVD Feature: a toolkit for feature-based collaborative filtering. J Mach \nLearn Res. 2012;13(1):3619–22.\n\n 27. Shi Y, Larson M, Hanjalic A. Collaborative filtering beyond the user-item matrix—a survey of the state of art and \nfuture challenges. ACM Comput Surv. 2014;47(1):3.\n\n 28. Shan H, & Banerjee A. Generalized probabilistic matrix factorizations for collaborative filtering, In Data mining \n(ICDM), IEEE 10th international conference. 2010. p. 1025–30.\n\n 29. Salakhutdinov R, & Mnih A. Bayesian probabilistic matrix factorization using Markov chain Monte Carlo. In: Proc. of \nthe 25th int. conference on machine learning. 2008. p. 880–7.\n\n 30. Crawford M, Khoshgoftaar TM, Prusa JD, Richter AN, Al Najada H. Survey of review spam detection using machine \nlearning techniques. J Big Data. 2015;2(1):23.\n\n 31. Wietsma TA, Ricci F. Product reviews in mobile decision aid systems. Francesco: PERMID; 2005. p. 15–8.\n 32. Jianguo C, et al. A disease diagnosis and treatment recommendation system based on big data mining and cloud \n\ncomputing. Inform Sci. 2018;435:124–49.\n 33. Manek AS, Shenoy PD, Mohan MC, Venugopal KR. Aspect term extraction for sentiment analysis in large movie \n\nreviews using Gini-index feature selection method and SVM classifier. World Wide Web. 2017;20:135–54. https ://doi.\norg/10.1007/s1128 0-015-0381-x.\n\n 34. Fan RE, Chang K-W, Hsieh C-J, Wang X-R, Lin C-J. LIBLINEAR: A library for large linear classification. J Mach Learn Res. \n2008;9:1871–4.\n\nhttps://doi.org/10.1007/978-3-540-68880-8_32\nhttps://doi.org/10.1007/s11280-015-0381-x\nhttp://dx.doi.org/10.1109/iccict.2012.6398180\nhttps://doi.org/10.1109/hpcc.and.euc.2013.106\nhttps://doi.org/10.1109/hpcc.and.euc.2013.106\nhttps://doi.org/10.1080/00207543.2015.1066519\nhttps://doi.org/10.1145/2939672.2939881\nhttps://doi.org/10.1371/journal.pone.0194889\nhttps://doi.org/10.18187/pjsor.v8i3.535\nhttps://doi.org/10.1007/s11280-015-0381-x\nhttps://doi.org/10.1007/s11280-015-0381-x\n\n\nPage 15 of 15Narayanan et al. J Big Data            (2020) 7:13  \n\n 35. Ribeiro MT, Singh S, and Guestrin C. Why should I trust you?: Explaining the predictions of any classifier. In: Proc. \nACMSIGKDD Int. Conf. Knowl. Discov. Data Mining. 2016. p. 1135–44.\n\n 36. Luo X, et al. An effective scheme for QoS estimation via alternating direction method-based matrix factorization. \nIEEE Trans Serv Comput. 2019;12(4):503–18.\n\n 37. Liu CL, Hsaio WH, Lee CH, Lu GC and Jou E. Movie rating and review summarization in mobile environment. In: IEEE \ntrans. systems, man and cybernetics, Part C: applications and reviews. 2012. p. 397–407.\n\n 38. Vapnik, VN. The nature of statistical learning theory, Springer, 2nd ed, 1999. Translated by Xu Jianghua, Zhang Xue-\ngong. Beijing: China Machine Press; 2000.\n\n 39. [Dataset] Flipkart-products. http://www.kaggl e.com/Promp tClou dHQ/flipk art-produ cts.\n 40. [Dataset] https ://snap.stanf ord.edu/data/web-Amazo n.html.\n 41. [Dataset] He R, McAuley J. Ups and downs: modeling the visual evolution of fashion trends with one-class collabora-\n\ntive filtering. WWW; 2016.\n 42. Popescu AM, Etzioni O. Extracting product features and opinions from reviews. 2005; EMNLP.\n 43. Zaharia M, Chowdhury M, Das T, Dave A, Ma J, McCauley M, Franklin M, Shenker S, Stoica I. Resilient distributed \n\ndatasets: A fault-tolerant abstraction for in-memory cluster computing Technical Report UCB/EECS-2011-82. UC \nBerkeley: EECS Department; 2011.\n\n 44. Davis J, Goadrich M. The relationship between precision-recall and ROC curves, In ICML. 2006. p. 233–40.\n 45. Lee JS, Lee ES. Exploring the usefulness of predicting people’s locations. Procedia Soc Beh Sci. 2014. https ://doi.\n\norg/10.1016/j.sbspr o.2014.04.451.\n\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nhttp://www.kaggle.com/PromptCloudHQ/flipkart-products\nhttps://snap.stanford.edu/data/web-Amazon.html\nhttps://doi.org/10.1016/j.sbspro.2014.04.451\nhttps://doi.org/10.1016/j.sbspro.2014.04.451\n\n\tImproving prediction with enhanced Distributed Memory-based Resilient Dataset Filter\n\tAbstract \n\tIntroduction\n\tRelated work\n\tMethodology\n\tData collection phase\n\tDataset pre-processing\n\tResilient Distributed Dataset\n\n\tPrediction classifiers\n\tLogistic regression (LR)\n\tSupport Vector Machine (SVM)\n\n\tExperimental setup\n\n\tResults and discussions\n\tConclusion and future work\n\tAcknowledgements\n\tReferences\n\n\n\n\n",
      "metadata_storage_path": "aHR0cHM6Ly9kZWZhdWx0cmVzb3VyY2Vncm91YWFkMy5ibG9iLmNvcmUud2luZG93cy5uZXQvY3VyYXRlZC1saWJyYXJ5L3M0MDUzNy0wMjAtMDAyOTIteS5wZGY1",
      "metadata_content_type": "application/pdf",
      "metadata_language": "en",
      "metadata_author": "Sandhya Narayanan ",
      "metadata_title": "Improving prediction with enhanced Distributed Memory-based Resilient Dataset Filter",
      "metadata_creation_date": "2020-02-24T16:27:45Z",
      "organizations": [
        "ket",
        "Creative Commons",
        "Creative",
        "creat iveco \nmmons",
        "School of Engineering",
        "Cochin University of Science",
        "Cus",
        "positive",
        "LSA",
        "relational database management systems",
        "huge",
        "Sup",
        "Real",
        "f2",
        "fk",
        "ith",
        "Ef",
        "Resilient Distributed",
        "RDD",
        "DMRDF",
        "KCm",
        "KRi",
        "zi",
        "yi",
        "hyper plane",
        "rc",
        "ge",
        "TP",
        "TN",
        "FP",
        "FN",
        "Gini",
        "Classifier",
        "Gini-index",
        "performance evaluation",
        "prediction",
        "TP + FN",
        "SVM",
        "SN",
        "PS",
        "Cochin University of Science & Technology",
        "Department of Computer Science",
        "of Ship Technology",
        "netflix",
        "Int J Electron",
        "& computing",
        "ICCICT",
        "institute of electrical and electronics engineers",
        "IEEE",
        "CloudCom",
        "ACM",
        "Int Conference Electron Comm",
        "ACM SIGKDD",
        "J Big Data",
        "J",
        "ACMSIGKDD Int.",
        "Springer",
        "China Machine Press",
        "Flipkart",
        "UCB",
        "UC",
        "EECS Department",
        "Springer Nature"
      ],
      "people": [
        "Sandhya Narayanan1",
        "Philip Samuel2",
        "Mariamma Chacko3",
        "Narayanan",
        "Makridakis",
        "15Narayanan",
        "Hao",
        "Salakhutdinov",
        "Wietsma",
        "Jianguo Chen",
        "Asha",
        "Luo",
        "Liu",
        "�G",
        "Iden",
        "MC",
        "Lau RY",
        "Liao SY",
        "Kwok RC",
        "Xu K",
        "Xia Y",
        "Li Y",
        "Lin X",
        "Wang X",
        "Matos CAD",
        "Rossi CAV",
        "Jeon S",
        "Dave K",
        "Lawrence S",
        "Pennock D.",
        "Zhou Y",
        "Wilkinson D",
        "Schreiber R",
        "Pan R.",
        "Zhang KZK",
        "Benyoucef M.",
        "Cui Geng",
        "Lui Hon-Kwong",
        "Guo Xiaoning",
        "Manek AS",
        "Shenoy PD",
        "Mohan MC",
        "Singh S",
        "Singh N.",
        "Demchenko Yuri",
        "Sihong Xie",
        "Guan Wang",
        "Shuyang Lin",
        "Yu Philip S.",
        "Koren Y",
        "Bell R",
        "Volinsky C.",
        "Salakhutdinov R",
        "Mnih A",
        "Hinton G.",
        "Hao MA",
        "Lyu MR",
        "Bandakkanavar V",
        "Ramesh M",
        "Geeta V",
        "Gu V",
        "Li H.",
        "Zhang Hanpeng",
        "Wang Zhaohua",
        "Chen Shengjun",
        "Guo Chengqi",
        "Ghose A",
        "Ipeirotis PG",
        "Chong AY",
        "Ch’ng E",
        "Liu MJ",
        "Li B.",
        "Yang H",
        "Fujimaki R",
        "Kusumura Y",
        "Liu J.",
        "Breese JS",
        "Heckerman D",
        "Kadie C",
        "Mukherjee A",
        "Kumar A",
        "Liu B",
        "Wang J",
        "Hsu M",
        "Castellanos M",
        "Ghosh R.",
        "Makridakis S",
        "Spiliotis E",
        "Assimakopoulos V.",
        "Imon A",
        "Roy C",
        "Manos C",
        "Bhattacharjee S.",
        "Chen T",
        "Zhang W",
        "Lu Q",
        "Chen K",
        "Zheng Z",
        "Yu Y.",
        "J Mach",
        "Shi Y",
        "Larson M",
        "Hanjalic A.",
        "Shan H",
        "Banerjee A",
        "Mnih A.",
        "Crawford M",
        "Khoshgoftaar TM",
        "Prusa JD",
        "Richter AN",
        "Al Najada H",
        "Wietsma TA",
        "Ricci F",
        "Francesco",
        "Jianguo C",
        "Venugopal KR",
        "Fan RE",
        "Chang",
        "Hsieh",
        "Wang",
        "Lin",
        "Ribeiro MT",
        "Guestrin C",
        "Luo X",
        "Liu CL",
        "Hsaio WH",
        "Lee CH",
        "Lu GC",
        "Jou E",
        "Xu Jianghua",
        "Zhang Xue-",
        "McAuley J.",
        "Popescu AM",
        "Etzioni O.",
        "Zaharia M",
        "Chowdhury M",
        "Das T",
        "Dave A",
        "Ma J",
        "McCauley M",
        "Franklin M",
        "Shenker S",
        "Stoica I",
        "Davis J",
        "Goadrich M.",
        "Lee JS"
      ],
      "keyphrases": [
        "Distributed Memory‑based Resilient Dataset Filter",
        "Creative Commons Attribution 4.0 International License",
        "Distributed Memory-based Resilient Dataset Filter",
        "other third party material",
        "big data processing technologies",
        "A Feature Information Gain",
        "other online shopping sites",
        "Resilient Distribution Dataset",
        "social networking sites",
        "Creative Commons licence",
        "sophisticated pre-processing techniques",
        "significant feature identification",
        "Support vector machine",
        "Redundancy Open Access",
        "J Big Data",
        "successful product launch",
        "online product recommendations",
        "consumer electronics market",
        "online product reviews",
        "distributed environment",
        "Online reviews",
        "pre-processed dataset",
        "feature modelling",
        "Online feedback",
        "retail shopping",
        "useful information",
        "price information",
        "author information",
        "Customer reviews",
        "duplicate reviews",
        "product sale",
        "product life",
        "product quality",
        "less product",
        "product pre-launch",
        "Sandhya Narayanan1",
        "Philip Samuel2",
        "Mariamma Chacko3",
        "massive volumes",
        "different applications",
        "sensor data",
        "health care",
        "enormous size",
        "unstructured data",
        "crucial thing",
        "large size",
        "communication methods",
        "direct suggestions",
        "several advantages",
        "limited time",
        "research work",
        "FIG) measure",
        "Logistic regression",
        "resilience property",
        "appropriate credit",
        "original author",
        "credit line",
        "statutory regulation",
        "copyright holder",
        "creat iveco",
        "RESEARCH Narayanan",
        "Cochin University",
        "Full list",
        "new product",
        "1 Information Technology",
        "intended use",
        "permitted use",
        "mation source",
        "DMRDF method",
        "The Author",
        "doi.org",
        "prediction accuracy",
        "Introduction",
        "Extracting",
        "amount",
        "extensive",
        "customers",
        "impact",
        "extent",
        "ratings",
        "Abstract",
        "sustainability",
        "companies",
        "turn",
        "reliability",
        "classifiers",
        "output",
        "manufacturer",
        "design",
        "Keywords",
        "article",
        "sharing",
        "adaptation",
        "reproduction",
        "medium",
        "link",
        "changes",
        "images",
        "permission",
        "Correspondence",
        "nairsands",
        "School",
        "Engineering",
        "Science",
        "Kochi",
        "India",
        "creativecommons",
        "licenses",
        "crossmark",
        "crossref",
        "different natural language processing techniques",
        "significant data processing methods",
        "big data processing model",
        "Different feature selection methods",
        "wrapper feature selection method",
        "new prod- uct",
        "multiple forecasting field",
        "previous customer feedbacks",
        "online shopping sites",
        "structured massive volume",
        "customer review analysis",
        "spam reviews recognition",
        "many redundant reviews",
        "machine learning methods",
        "Consumer product success",
        "product pre-launch prediction",
        "future work” section",
        "user rating matrix",
        "poor quality products",
        "different criteria",
        "Different works",
        "wrapper methods",
        "art methods",
        "alternative methods",
        "statistical methods",
        "model complexity",
        "statistical analysis",
        "filter method",
        "customer reviews",
        "enhanced method",
        "unreliable data",
        "model performance",
        "shop owners",
        "other hand",
        "extra cost",
        "brand loyalty",
        "eCommerce firms",
        "other retailers",
        "large volume",
        "crucial phase",
        "univariate manner",
        "System design",
        "less accuracy",
        "unknown values",
        "improper knowledge",
        "Matrix factorization",
        "collaborative filtering",
        "two vectors",
        "low dimensionality",
        "accurate reviews",
        "duplicated reviews",
        "negative reviews",
        "Related work",
        "product reviews",
        "odology” section",
        "data pre-processing",
        "marketing strategies",
        "embedded process",
        "prediction classifiers",
        "Page",
        "15Narayanan",
        "information",
        "effort",
        "industry",
        "strategy",
        "users",
        "valuable",
        "number",
        "blogs",
        "forums",
        "awareness",
        "need",
        "ratio",
        "positive",
        "features",
        "usefulness",
        "relevance",
        "state",
        "gener",
        "ally",
        "combination",
        "distributive",
        "web",
        "order",
        "scalable",
        "failure",
        "realization",
        "paper",
        "methodology",
        "Results",
        "discussions",
        "conclusion",
        "Makridakis",
        "Author",
        "reason",
        "MF",
        "Hao",
        "item",
        "user item matrix factorization technique",
        "standard probability-based matrix factorization methods",
        "user item matrix factorization method",
        "ity related matrix factorization",
        "Gini- index impurity measure",
        "relational database management systems",
        "single value decomposition method",
        "high term frequency words",
        "probability factorization methods",
        "student user behavior",
        "Stochastic Gradient Decent",
        "mobile decision aid",
        "rule-based apriori algorithm",
        "mobile envi- ronment",
        "appropriate computing models",
        "traditional collaborative Filtering",
        "product feature identification",
        "Bayesian-based probabilistic analysis",
        "cold start problem",
        "automatic service selection",
        "Latent Semantic Analysis",
        "Gini-index feature method",
        "movie review dataset",
        "customer review datasets",
        "pre-launch product prediction",
        "Statistical methods",
        "user reviews",
        "opinion words",
        "Gini-index method",
        "filtering function",
        "movie rating",
        "review summarization",
        "customer feedback",
        "density-peaked method",
        "LSA-based) method",
        "LSA-based method",
        "squared distance",
        "big volume",
        "conventional approach",
        "implementation purpose",
        "sparsity problem",
        "various analyses",
        "recommendation issues",
        "different websites",
        "Jianguo Chen",
        "opinion extraction",
        "individual dimensions",
        "large datasets",
        "major challenge",
        "existing products",
        "different classifiers",
        "rating dataset",
        "polarity prediction",
        "product features",
        "recommender system",
        "recommendation system",
        "huge volume",
        "historical data",
        "big data",
        "disease symptoms",
        "sentimental analysis",
        "diction accuracy",
        "29 features",
        "solution",
        "squares",
        "Salakhutdinov",
        "other",
        "items",
        "limitation",
        "addition",
        "approaches",
        "Wietsma",
        "study",
        "result",
        "correlation",
        "treatment",
        "diagnosis",
        "diseases",
        "cluster",
        "Asha",
        "sentences",
        "rence",
        "document",
        "precision",
        "disadvantage",
        "Luo",
        "quality",
        "Liu",
        "authors",
        "Lack",
        "redundancy",
        "work",
        "existence",
        "Methodology",
        "phases",
        "Distributed Memory-based Resilient Dataset Filter approach",
        "Identification Redundancy Removal Data Integration Training",
        "classification algorithms Support Vector Logistic",
        "Product prelaunch prediction System Design",
        "Data collection Categorical Text Real",
        "Enhanced Feature Information Gain measure",
        "flip cart customer reviews",
        "ith customer review Ri",
        "Regression Support Vector",
        "duplicate data removal",
        "classification algorithms Logistic",
        "mobile phones product reviews",
        "port Vector Machine",
        "data collection phase",
        "JSON file format",
        "New mobile phones",
        "product rating scale",
        "categorical, real",
        "Regression Testing Dataset",
        "Dataset pre‑processing",
        "product review dataset",
        "text data",
        "Logistic Regression",
        "opinion identification",
        "data pre",
        "best information",
        "prediction classifier",
        "multivariate data",
        "pre-launch prediction",
        "Product feature",
        "input dataset",
        "Product categories",
        "feature selection",
        "processing Feature",
        "nificant feature",
        "feature instance",
        "k feature",
        "various stages",
        "dancy elimination",
        "different products",
        "Several datasets",
        "public datasets",
        "data- set",
        "seven brands",
        "two reasons",
        "unavoidable items",
        "sample set",
        "catego- rization",
        "priority weightage",
        "major role",
        "large number",
        "fea- tures",
        "total number",
        "particular review",
        "user requirements",
        "feature impurity",
        "market industry",
        "Battery life",
        "Review Content",
        "user features",
        "Figure",
        "model",
        "SVM",
        "LR",
        "zon",
        "period",
        "24 months",
        "day",
        "everyone",
        "Table",
        "ReviewID",
        "Title",
        "price",
        "camera",
        "RAM",
        "Fig.",
        "processor",
        "Average",
        "polarity",
        "opinions",
        "Senti-WordNet",
        "probability",
        "fk",
        "SR",
        "Distributed Memory-based Resilience Dataset Filter",
        "15 Rear camera 31 Finger sensor",
        "big data processing approach",
        "launch predic- tion",
        "Resilient Distributed Dataset",
        "local file system",
        "3 ReviewID 19 Product category",
        "Impurity R(I",
        "value) pair dataset",
        "memory data caching",
        "information Gain value",
        "Feature Information Gain",
        "customer review dataset",
        "Table 2 Significant Features",
        "Ef Review Feature",
        "13 Operating system",
        "input file",
        "P(R",
        "25 Front camera",
        "new dataset",
        "prior information",
        "9 Feature information",
        "Next step",
        "OR N",
        "Sim type",
        "4 Content 20 Thickness",
        "mobile phone",
        "7 Battery life",
        "10 Review type",
        "29 Network support",
        "14 Water proof",
        "Quick charging",
        "32 Internal storage",
        "machine learning",
        "pervasive requirement",
        "main actions",
        "first element",
        "main Transformations",
        "long Lineage",
        "n customers",
        "feature set",
        "active customer",
        "5 Product brand",
        "Product type",
        "11 Product display",
        "redundant reviews",
        "N reviews",
        "value) pairs",
        "�G value",
        "null values",
        "Pi.log2Ef",
        "SR N",
        "cache chunks",
        "24 Product rating",
        "reduce function",
        "SR.",
        "respect",
        "opinion",
        "No",
        "1 Author",
        "17 RAM",
        "2 Title",
        "Weight",
        "8 Price",
        "12 Processor",
        "Multi-band",
        "16 Applications",
        "RDD",
        "requirements",
        "Variety",
        "jobs",
        "point",
        "time",
        "challenge",
        "analysis",
        "systems",
        "elements",
        "saveAsSequenceFile",
        "path",
        "map",
        "groupBykey",
        "ReduceBykey",
        "fault-tolerance",
        "list",
        "Fx",
        "∑",
        "β",
        "Distributed Memory-based resilient filter score",
        "hyper plane normal vector element",
        "memory-based Resilient Dataset Filter score",
        "D dimensional input space",
        "resilient filter score value",
        "Support Vector Machine classifiers",
        "t training feature vectors",
        "one Distributed Memory-based",
        "decision hyper plane",
        "positive one class",
        "logarithmic base value",
        "logistic regression analysis",
        "machine learning method",
        "prediction variable value",
        "Logistic regression value",
        "data features relationships",
        "product failure class",
        "product success class",
        "δ score value",
        "row vector",
        "column vector",
        "Prediction classifiers",
        "significant feature",
        "corresponding vectors",
        "nearest vectors",
        "learning approaches",
        "classification method",
        "training dataset",
        "constant value",
        "probability value",
        "mth customer",
        "L1 norm",
        "second occurrence",
        "case study",
        "mobile phones",
        "logit function",
        "+ b",
        "new skills",
        "data separation",
        "real numbers",
        "two classes",
        "mth review",
        "ith review",
        "customer review",
        "similar reviews",
        "successful products",
        "N’ number",
        "KC",
        "KR",
        "KFx",
        "KFj",
        "entry",
        "similarities",
        "The",
        "Eq.",
        "processing",
        "More",
        "market",
        "p0",
        "L0",
        "values",
        "knowledge",
        "RD",
        "XD",
        "way",
        "distance",
        "hyperplane",
        "conditions",
        "margin",
        "γ",
        "different Spark cluster configura- tions",
        "Most significant customer review features",
        "two Intel Xeon E",
        "2699V4 2.2 G Hz processors",
        "Web Server Gateway Interface",
        "customer review feature identification",
        "big data processing system",
        "software system large servers",
        "LSA-based methods processing time",
        "big data analytics",
        "Apache web server",
        "Amazon Web Services",
        "Apache Spark 2.2.1 framework",
        "Logistic regression classifiers",
        "system perfor- mance",
        "different dataset size",
        "feature information gain",
        "negative one class",
        "semantic analysis methods",
        "high-speed processing performance",
        "system response time",
        "Spark python API",
        "several case studies",
        "system design factors",
        "mobile phone sustainability",
        "prediction accuracy measurement",
        "redundant customer reviews",
        "prediction accuracy evaluation",
        "DMRDF model time",
        "proposed system",
        "separate servers",
        "prediction system",
        "failure class",
        "software components",
        "LSA-based model",
        "less time",
        "product sustainability",
        "Experimental setup",
        "PySpark version",
        "Vector Machine",
        "predic- tion",
        "major concern",
        "internal storage",
        "art techniques",
        "DMRDF approach",
        "9 GB dataset",
        "18 GB dataset",
        "DMRDF model 740",
        "other gini-index",
        "Product price",
        "scalability requirements",
        "other state",
        "Gini-index model",
        "application development",
        "16 GB",
        "gramming",
        "Ubuntu",
        "nodes",
        "VCPUs",
        "4 cores",
        "wtzi",
        "Support",
        "7 brands",
        "LR.",
        "graph",
        "percentage",
        "manner",
        "comparison",
        "completion",
        "latent",
        "342 s",
        "495 s",
        "156 s",
        "910 s",
        "advantage",
        "execution",
        "recall",
        "Distributed Memory-based Resilient Dataset Filter method",
        "reliable big data processing model",
        "Support Vector Machine prediction classifiers",
        "Support Vector Machine classification",
        "Classifier Support vector machine",
        "different customer review aspects",
        "customer review feature prediction",
        "Processing Time Graph",
        "big data analysis",
        "Months LSA-based DMRDF Gini-index",
        "LSA-based meth- ods",
        "Logistic Regression classifiers",
        "other two methods",
        "duplicate customer reviews",
        "Classifier Logistic regression",
        "LR classifiers",
        "redundant data",
        "feature dimensionality",
        "other methods",
        "Gini-index methods",
        "Dataset size",
        "Gini-index approaches",
        "significant features",
        "LSA-based approaches",
        "accuracy measures",
        "P@R",
        "R@R",
        "false negative",
        "1GB 5GB",
        "SVM classifier",
        "ratings datasets",
        "performance evaluation",
        "Gini- index",
        "Technological development",
        "new challenges",
        "artificial intelligence",
        "next frontier",
        "mation Gain",
        "The DMRDF",
        "large dataset",
        "many features",
        "Performance comparison",
        "future work",
        "PA measures",
        "results",
        "TP",
        "FP",
        "TN",
        "FN",
        "Eqs",
        "18GB",
        "tions",
        "Conclusion",
        "era",
        "innovation",
        "productivity",
        "implementation",
        "elimination",
        "12",
        "7",
        "ACM Trans Manag Inform Syst",
        "Int J Softw Eng Appl",
        "efficient big data search processing",
        "Int J Inform Manag.",
        "J Acad Market Sci",
        "Large-scale parallel collaborative filtering",
        "different reliable online websites",
        "Redundant data removal technique",
        "Promp tClou dHQ/flipk art",
        "other product feature identification",
        "online review spam detection",
        "Int J Electron",
        "data processing domains",
        "Dec Support Syst",
        "Feature information gain",
        "statistical prop- erties",
        "new product sales",
        "prediction model- ling",
        "Pre-launch product prediction",
        "information fusion approach",
        "memory computation method",
        "online consumer reviews",
        "ing matrix factorization",
        "time streaming predictions",
        "Latent semantic analysis",
        "Social commerce research",
        "dataset model performance",
        "Prediction accuracy",
        "meta-analytic review",
        "literature review",
        "research themes",
        "semantic classification",
        "Consumer behavior",
        "ratings dataset",
        "important role",
        "applica- tion",
        "Resilience property",
        "long lineage",
        "unified API",
        "customer comments",
        "learning algorithms",
        "major contributor",
        "current study",
        "produ cts",
        "Competing interests",
        "Author details",
        "Lau RY",
        "Liao SY",
        "Kwok RC",
        "Xu K",
        "Xia Y",
        "Li Y.",
        "Text mining",
        "probabilistic modeling",
        "Lin X",
        "Wang X",
        "Matos CAD",
        "Rossi CAV",
        "mouth communications",
        "Jeon S",
        "Dave K",
        "Lawrence S",
        "Pennock D.",
        "peanut gallery",
        "Zhou Y",
        "Wilkinson D",
        "Schreiber R",
        "Pan R.",
        "netflix prize",
        "Zhang KZK",
        "Benyoucef M.",
        "Cui Geng",
        "Lui Hon-Kwong",
        "Guo Xiaoning",
        "Manek AS",
        "Shenoy PD",
        "Proposed design",
        "final manuscript",
        "Kaggle repository",
        "Mohan MC",
        "Ship Technology",
        "Authors’ contributions",
        "DMRDF model",
        "Computer Science",
        "real",
        "surveys",
        "thesis",
        "sentiments",
        "limitations",
        "Abbreviations",
        "FIG",
        "LSA",
        "Precision",
        "Recall",
        "Acknowledgements",
        "SN",
        "PS",
        "Funding",
        "Availability",
        "materials",
        "datasets",
        "stanford",
        "Amazon",
        "2 Department",
        "3 Department",
        "25 October",
        "PromptCloudHQ",
        "flipkart-products",
        "References",
        "definition",
        "trends",
        "Word",
        "marketing",
        "antecedents",
        "moderators",
        "WWW",
        "effect",
        "Comm.",
        "17",
        "Mnih A. Bayesian probabilistic matrix factorization",
        "ACM Trans Intell Syst Technol",
        "Volinsky C. matrix factorization technique",
        "Pak J Stat Oper Res",
        "Int J Knowl Web Intell",
        "22nd ACM SIGKDD Int. Conference",
        "19th ACM SIGKDD international conference",
        "Liu J. Online Feature Selection",
        "Generalized probabilistic matrix factorizations",
        "Markov chain Monte Carlo",
        "Int Conference Electron Comm",
        "21st international conference companion",
        "2013 IEEE 10th Int. Con.",
        "Int J Prod Res",
        "IEEE 4th Int. conference",
        "novel review ranking systems",
        "IEEE 10th international conference",
        "Yu Y. SVD Feature",
        "Machine Learning forecasting methods",
        "World Wide Web",
        "J Inform Manag.",
        "ACM Comput Surv.",
        "implicit social relations",
        "Yu Philip S.",
        "online shopping websites",
        "scientific data infrastructure",
        "time-series pattern discovery",
        "Ch’ng E",
        "consumer product demands",
        "Big data analytics",
        "cloud computing technology",
        "Li H. Memory",
        "big data challenges",
        "2012 international conference",
        "feature-based collaborative filtering",
        "user-item matrix",
        "J Mach",
        "Wang J",
        "recommender systems",
        "Liu MJ",
        "online promotional",
        "Liu B",
        "Kadie C.",
        "Roy C",
        "Manos C",
        "malicious websites",
        "Koren Y",
        "Product recommendation",
        "Ghose A",
        "Li B.",
        "online reviews",
        "Kusumura Y",
        "Mukherjee A",
        "Kumar A",
        "Knowledge discovery",
        "data mining",
        "Spiliotis E",
        "Imon A",
        "Shi Y",
        "Hanjalic A.",
        "future challenges",
        "Banerjee A.",
        "ACM Proceedings",
        "high-performance computing",
        "Yang H",
        "Shan H",
        "Singh S",
        "Makridakis S",
        "Bhattacharjee S",
        "Singh N.",
        "electronics engineers",
        "Demchenko Yuri",
        "Sihong Xie",
        "Shuyang Lin",
        "Bell R",
        "Salakhutdinov R",
        "Hinton G",
        "boltzmann machines",
        "Hao MA",
        "King I",
        "Lyu MR",
        "Bandakkanavar V",
        "Ramesh M",
        "Geeta V.",
        "sentiment classification",
        "Gu V",
        "iterative operation",
        "Zhang Hanpeng",
        "Chen Shengjun",
        "Guo Chengqi",
        "working communities",
        "empirical study",
        "Ipeirotis PG",
        "Chong AY",
        "Fujimaki R",
        "Breese JS",
        "Heckerman D",
        "Empirical analysis",
        "predictive algorithms",
        "14th Conf.",
        "Artifical Intelligence",
        "Hsu M",
        "Castellanos M",
        "Ghosh R.",
        "opinion spammers",
        "behavioral footprints",
        "Assimakopoulos V",
        "PLoS ONE",
        "logistic regression",
        "Chen T",
        "Zhang W",
        "Lu Q",
        "Chen K",
        "Zheng Z",
        "Larson M",
        "dx.doi",
        "Guan Wang",
        "Res.",
        "spam detection",
        "fraudulent",
        "communication",
        "ICCICT",
        "institute",
        "electrical",
        "science",
        "CloudCom",
        "Computer",
        "Proc.",
        "24th",
        "explicit",
        "survey",
        "IJRITCC",
        "hadoop",
        "spark",
        "hpcc",
        "Zhaohua",
        "mediator",
        "roles",
        "Uncertainty",
        "Chicago",
        "Statistical",
        "concerns",
        "journ",
        "Prediction",
        "rainfall",
        "pjsor",
        "toolkit",
        "ICDM",
        "memory cluster computing Technical Report UCB/EECS",
        "alternating direction method-based matrix factorization",
        "ACMSIGKDD Int. Conf. Knowl. Discov.",
        "Al Najada H. Survey",
        "Gini-index feature selection method",
        "Jou E. Movie rating",
        "Procedia Soc Beh Sci",
        "mobile decision aid systems",
        "IEEE Trans Serv Comput",
        "Ricci F. Product reviews",
        "25th int. conference",
        "Stoica I. Resilient",
        "treatment recommendation system",
        "Aspect term extraction",
        "large linear classification",
        "Promp tClou dHQ",
        "flipk art-produ cts",
        "large movie reviews",
        "China Machine Press",
        "Support Vector Machine",
        "statistical learning theory",
        "A disease diagnosis",
        "Related work Methodology",
        "machine learning techniques",
        "McAuley J. Ups",
        "Data collection phase",
        "big data mining",
        "cloud computing",
        "trans. systems",
        "Inform Sci",
        "mobile environment",
        "Dave A",
        "Ma J",
        "Davis J",
        "Crawford M",
        "Khoshgoftaar TM",
        "Prusa JD",
        "Richter AN",
        "Wietsma TA",
        "Jianguo C",
        "Venugopal KR",
        "sentiment analysis",
        "Fan RE",
        "Chang K-W",
        "Hsieh C-J",
        "Wang X-R",
        "Lin C-J.",
        "Ribeiro MT",
        "Guestrin C.",
        "Luo X",
        "effective scheme",
        "QoS estimation",
        "Liu CL",
        "Hsaio WH",
        "Lee CH",
        "Lu GC",
        "Part C",
        "2nd ed",
        "Xu Jianghua",
        "He R",
        "visual evolution",
        "fashion trends",
        "Popescu AM",
        "Etzioni O.",
        "Zaharia M",
        "Chowdhury M",
        "Das T",
        "McCauley M",
        "Franklin M",
        "Shenker S",
        "fault-tolerant abstraction",
        "EECS Department",
        "Goadrich M.",
        "ROC curves",
        "Lee JS",
        "Lee ES",
        "jurisdictional claims",
        "institutional affiliations",
        "Improving prediction",
        "Acknowledgements References",
        "snap.stanford",
        "Springer Nature",
        "Francesco",
        "PERMID",
        "LIBLINEAR",
        "library",
        "iccict",
        "journal",
        "pone",
        "predictions",
        "summarization",
        "cybernetics",
        "applications",
        "Vapnik",
        "VN.",
        "gong",
        "Beijing",
        "Flipkart-products",
        "kaggl",
        "downs",
        "filtering",
        "EMNLP.",
        "Berkeley",
        "relationship",
        "precision-recall",
        "ICML",
        "people",
        "locations",
        "sbspr",
        "Publisher",
        "Note",
        "regard",
        "maps"
      ]
    }
  ]
}